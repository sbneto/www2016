\section{Data: Reddit as a community}

%% DC 15: The citations here, just to give exmples of work that asks these questions in various ways.
%% Sam 17: Missing ``kinds of things'' citations.
In this paper, we explore how cohort based analysis can give us deeper insights into three common questions about online communities: how active are users \cite{Scellato2011,Hughes2009,Java2007,Levy1984}, how much do they contribute \cite{Scellato2011,Gruhl2004,Guo2009}, and what kinds of work do they engage in \cite{Welser2011,Choi2010,Panciera2009}?  We do this in the context of Reddit, beginning with a brief overview of both Reddit and the dataset that we use in this paper, focusing on aspects that directly impact our analyses\footnote{There is more to say about Reddit itself (see \url{https://www.Reddit.com/about/ }).}.


\subsection{What is Reddit, briefly}

%% DC 10: Will want a couple of legible screenshots here to help illustrate.
%% DC 15: Ideally we would get these numbers as of the end of the dataset to be more consistent.
Reddit is one of the largest sharing and discussion communities on the Web.  According to Alexa, as of late 2015 Reddit is in the top 15 sites in the U.S. and the top 35 in the world in terms of monthly unique visitors.  It consists of a large number of subreddits (853,000 as of June 21st, 2015\footnote{\url{http://www.Redditblog.com/2015/06/happy-10th-birthday-to-us-celebrating.html }for more numbers on Reddit size.}), each of which focuses on a particular purpose.  Many subreddits are primarily about sharing web content from other sites: in ``Pics'', ``News'', ``Funny'', ``Gaming', and many other communities, users (``Redditors'') make ``submissions'' of links posted at other sites that they think are interesting.  In other subreddits, Redditors primarily write text-based ``self-posts'': ``AskReddit'', ``IamA'', ``ShowerThoughts'' are places where people can ask questions and share stories of their own lives.  Generically, we will refer to submissions and text posts as ``submissions''.  

Each post can be imagined as the root of a threaded comment tree; in addition to submitting, Redditors can make comments, and vote on both submissions and comments.  Votes are used both to sort comments within a submission and submissions within a subreddit, and also form the basis of ``karma'', a reputation system that essentially tracks how often people upvote a given Redditor's comments and submitted links.  Redditors can also create subreddits and volunteer to moderate them.

We choose Reddit as our target community for a number of reasons.  It has existed since 2005, meaning that there has been ample time for the community to evolve and for differences in user cohorts to appear.  Second, it is one of the most popular online communities, allowing different types of contributions---comments and original submissions---across many different subreddits.%being composed of a number of diverse subreddits allows us to explore questions of how communities diverge over time.  
Third, Reddit data are publicly available through an API.

\subsection{The dataset}

Redditor \textit{Stuck\_In\_The\_Matrix} used Reddit's API to compile a dataset of almost every publicly available comment \footnote{Available in \url{https://www.Reddit.com/r/datasets/comments/3bxlg7/i_have_every_publicly_available_Reddit_comment }.} from October 2007 until May 2015.  The dataset is composed of 1.65 billion comments, although due to API call failures, about 350,000 comments are unavailable.  He also compiled a submissions dataset for the period of October 2007 until December 2014 that was made available for us upon request, containing a total of 114 million submissions.  These datasets contain the JSON data objects returned by Reddit's API for comments and submissions \footnote{A full description of the JSON objects is available at \url{https://github.com/Reddit/Reddit/wiki/JSON }.}; for our purposes, the main items of interest were the UTC creation date, the username, the subreddit, and for comments, the comment text.

We focus on submissions and comments in the dataset because they have timestamps and can be tied to specific users and subreddits, allowing us to perform our time-based analyses.   In some analysis, we look only at comments; in some, we combine comments and submissions, calling them \textbf{``posts''}.  We would also like to have looked at voting behavior as a measure of user activity\footnote{This would also give us more insight than usual into lurkers' behavior; we'll return to this in the discussion.}, but individual votes with timestamps and usernames are not available through the API, only the aggregate number of votes that posts receive.

\subsection{Preprocessing the dataset}

To analyze the data, we used Google BigQuery \footnote{\url{https://cloud.google.com/bigquery/}.}, a big data processing tool.
% that, at the time of writing this paper, provided free processing for up to 1TB of data for users with a Google account.  
Redditor \textit{fhoffa} imported the comments into BigQuery and made them publicly available \footnote{See \url{https://www.Reddit.com/r/bigquery/comments/3cej2b/17_billion_Reddit_comments_loaded_on_bigquery/}.}.  We uploaded the submission data ourselves using Google's SDK.
% \footnote{Bigquery tools were still part of the alpha code in the SDK by the time.}.


%% Sam 17: I don't think there is such a thing as ``bot'' names conventions
For the analysis in the paper, we did light preprocessing to filter out posts by deleted users, posts with no creation time, and posts by authors with
% names that follow Reddit's conventions for auto-posting bots. 
bot-like names\footnote{Ending with ``\_bot'' or ``Bot''; or containing ``transcriber'' or ``automoderator''.}.

We also considered only comment data from October 2007 until December 2014 in order to have a matching period for comments and submissions. After this process, we had a total of 1.17 billion comments and 114 million submissions.

%% DC 15: I like big figures, but we could if needed scale/shrink these more to force page boundaries.  Things will change when the front part of the paper changes as well.
\begin{figure*}[!tb]
\centering
\subimage[width=0.48, scale=0.45]{./images/cumulative_users_subreddits.eps}
\subimage[width=0.48, scale=0.45]{./images/active_users_subreddits.eps}
\caption{Figure (a) shows the cumulative growth of Reddit for users and subreddits. Figure (b) shows the number of active users and subreddits in Reddit over time. An active user or subreddit is one that had at least one post (comment or submission) in the time bin we used---here, discretized by month.}
\label{fig:cumulative}
\end{figure*}

\subsection{An overview of the dataset}

Here we present an overview of the dataset that shows Reddit's overall growth.  Figure~\ref{fig:cumulative}a presents the cumulative number of user accounts and subreddits created as of the last day of every month. After an initial extremely rapid expansion from 2008--2009, both the number of users and subreddits have grown exponentially.  As of the end of 2014, about 16.2 million distinct users have made at least one post and 327,000 subreddits received at least one post based on our data.

However, as with many other online sites, most users \cite{Scellato2011,Hughes2009,Java2007} and communities \cite{Arguello2006} do not stay active. We define as an ``\textbf{active user}'' one that made at least one post in the month in question. Similarly, an ``\textbf{active subreddit}'' is one that received at least one post in the month. In December 2014, about 470,000 thousand users and 11,400 subreddits were active, both an order of magnitude less than the cumulative numbers. Figure~\ref{fig:cumulative}b shows the monthly number of active users and subreddits.

Our interest in this paper is not so much whether users survive as it is about the behavior of active users.  Thus, 
in general our analysis will look only at active users and subreddits in each month; those that are temporarily or permanently gone from Reddit are not included.  

\subsection{Identifying cohorts}

We define the ``\textbf{user's creation time}'' as the time of the first post made by that user.  Throughout this paper, we will use the notion of user cohorts, which will consist of users created in the same calendar year.

%% DC 15: This is not super-clear, but it is closer.
In many cases, we will look at the evolution of these cohorts. Since users can be created at any time during their cohort year, and our dataset ends in 2014, 
we are likely to have a variation on the data available for each user of up to one year, even though they are in the same cohort.  To deal with this, some of our cohorted analyses will consider only the overlapping time window for which we collect data for all users in a cohort.   This means that we are normally not going to include the 2014 cohort in our analyses.

Our data starts in October 2007, but Reddit existed before that. That means that, not only do we have incomplete data for the 2007 year (which compromises this cohort), but there might also be users and subreddits that show up in 2007 that were actually created in the previous years. Since we can not control for these, we will also omit 2007 cohort. We will, however, include 2007 in the overall analyses over time (the non cohorted ones) for two reasons: first, it does not have any direct impact in the results, only extends the axis for 3 extra months, and second, we often compare the cohorted approach with a naive approach based on aggregation, and we would not expect a naive approach to do such filtering. 
